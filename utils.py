from typing import Dict
from fastapi import HTTPException
import requests
from functools import lru_cache
from config import GEMINI_API_KEY, LLAMA_CHAT_API_URL, LLAMA_GENERATE_API_URL, MODEL_NAME, CACHE_MAX_SIZE
import traceback

from database import insert_transaction_pg
from postgre_db import TransactionCreate, get_categories, insert_bulk_transactions

@lru_cache(maxsize=CACHE_MAX_SIZE)
def cached_llama_call(prompt: str) -> dict:
    payload = {"model": MODEL_NAME, "prompt": prompt, "stream": False}
    response = requests.post(LLAMA_GENERATE_API_URL, json=payload)
    return response.json()

async def ocr_process(image_path: str) -> tuple[str, dict]:
    text = f"Chi 1000000 cho th·ª±c ph·∫©m t·∫°i VinMart, 2025-04-15"
    metadata = {"store": "VinMart", "location": "H√† N·ªôi"}
    return text, metadata

async def analyze_sentiment_advanced(text: str) -> tuple[str, float]:
    prompt = f"Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa vƒÉn b·∫£n sau: '{text}'"
    response = cached_llama_call(prompt)
    sentiment = "lo l·∫Øng" if "lo l·∫Øng" in text else "b√¨nh th∆∞·ªùng"
    score = 0.9 if "lo l·∫Øng" in text else 0.5
    return sentiment, score

async def extract_receipt_info_advanced(text: str) -> tuple[dict, dict]:
    parts = text.split(",")
    amount = float(parts[0].split()[-2])
    category = parts[0].split("cho")[-1].split("t·∫°i")[0].strip()
    date = parts[1].strip()
    metadata = {"store": parts[0].split("t·∫°i")[-1].strip(), "timestamp": "2025-04-15T10:00:00"}
    return {"date": date, "amount": amount, "category": category, "source": "bi√™n lai"}, metadata

async def predict_spending(transactions: list[dict]) -> list[dict]:
    total = sum(t["amount"] for t in transactions)
    return [{"date": "2025-05-01", "predicted_amount": total * 1.1, "category": "th·ª±c ph·∫©m", "confidence": 0.85}]


import re
import datetime
import httpx

async def extract_receipt_info_advanced(text: str):
    match = re.search(r'(\d+(?:[\.,]?\d+)?)(k|K|ngh√¨n|tr|tri·ªáu)?', text)
    if not match:
        raise ValueError("Kh√¥ng t√¨m th·∫•y s·ªë ti·ªÅn trong n·ªôi dung.")

    num = match.group(1).replace(",", "").replace(".", "")
    unit = match.group(2) or ""
    amount = float(num)

    if unit.lower() in ['k', 'ngh√¨n']:
        amount *= 1_000
    elif unit.lower() in ['tr', 'tri·ªáu']:
        amount *= 1_000_000

    transaction = {
        "amount": amount,
        "note": text,
    }
    metadata = {
        "source": "receipt",
        "raw_text": text
    }
    return transaction, metadata

# =============================
# 2. Rule-based fallback
# =============================
def classify_category(text: str) -> str:
    text = text.lower()

    categories = {
        "th·ª±c ph·∫©m": ["g·∫°o", "rau", "th·ªãt", "tr·ª©ng", "s·ªØa", "ƒÉn", "si√™u th·ªã", "vinmart"],
        "ti·ªÅn nh√†": ["thu√™ nh√†", "ti·ªÅn nh√†", "ph√≤ng tr·ªç", "nh√† nguy√™n cƒÉn"],
        "ti·ªÅn ƒëi·ªán": ["ti·ªÅn ƒëi·ªán", "h√≥a ƒë∆°n ƒëi·ªán", "evn"],
        "ti·ªÅn n∆∞·ªõc": ["ti·ªÅn n∆∞·ªõc", "h√≥a ƒë∆°n n∆∞·ªõc", "n∆∞·ªõc sinh ho·∫°t"],
        "ƒëi·ªán tho·∫°i / internet": ["viettel", "vina", "mobifone", "wifi", "data", "4g", "5g", "internet"],
        "ƒëi l·∫°i": ["grab", "taxi", "xƒÉng", "xe", "bus", "toll"],
        "gi·∫£i tr√≠": ["netflix", "karaoke", "xem phim", "r·∫°p", "game", "spotify"],
        "mua s·∫Øm": ["qu·∫ßn √°o", "gi√†y", "m·ªπ ph·∫©m", "shopee", "lazada", "tiki", "ph·ª• ki·ªán"],
        "gi√°o d·ª•c": ["h·ªçc ph√≠", "kh√≥a h·ªçc", "ti·∫øng anh", "s√°ch", "l·ªõp h·ªçc"],
        "y t·∫ø": ["thu·ªëc", "kh√°m", "b·ªánh vi·ªán", "hi·ªáu thu·ªëc", "y t·∫ø", "b·∫£o hi·ªÉm y t·∫ø"],
    }

    for category, keywords in categories.items():
        if any(kw in text for kw in keywords):
            return category

    return "kh√°c"

# =============================
# 3. LLM classification (Ollama /api/chat)
# =============================

GOOGLE_GEMINI_URL="https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"

async def classify_category_llm(text: str) -> tuple[str, str]:
    categories = await get_categories()
    categories_str = "\n".join([f"{cat.id}:{cat.name}" for cat in categories])
    print("CATEGORIES:")
    print(categories_str)
    print("TEXT:")
    prompt = f'T√¥i c√≥ m·ªôt danh s√°ch c√°c danh m·ª•c:\n{categories_str}.\nM·ªói danh m·ª•c c√≥ 1 uuid v√† t√™n, c√°ch nhau b·ªüi d·∫•u \":\".\nT√¥i s·∫Ω cho b·∫°n 1 c√¢u n√≥i, h√£y ph√¢n lo·∫°i n·ªôi dung c√¢u n√≥i ƒë√≥ v√†o m·ªôt trong c√°c nh√≥m danh m·ª•c tr√™n.\nCh·ªâ tr·∫£ l·ªùi ƒë√∫ng danh m·ª•c duy nh·∫•t theo c√∫ ph√°p "id:t√™n_danh_m·ª•c".\n\nS·ªë ti·ªÅn c√≥ th·ªÉ c√≥ ch·ª©a ƒë·∫•u ch·∫•m (.) ho·∫∑c d·∫•u ph·∫©y (,) ƒë·ªÉ ph√¢n c√°ch ph·∫ßn ngh√¨n. H√£y b·ªè qua c√°c k√≠ t·ª± n√†y V√≠ d·ª•: 500.000 => 500000 ho·∫∑c 500,000 => 500000\n\nC√¢u: \"{text}\"'
    try:
        async with httpx.AsyncClient(timeout=20.0) as client:
            res = await client.post(
                GOOGLE_GEMINI_URL,
                json={
                    "contents": [
                        {
                            "parts": [
                                {
                                    "text": prompt
                                }
                            ]
                        }
                    ]
                },
                params={
                    "key": GEMINI_API_KEY
                }
            )
            res.raise_for_status()
            data = res.json()
            text = data["candidates"][0]["content"]["parts"][0]["text"].strip().lower()
            print("API RESPONSE:")
            print(text)
            return text
    except Exception:
        print("‚ö†Ô∏è L·ªói khi ph√¢n lo·∫°i b·∫±ng LLM:")
        traceback.print_exc()
        
        return "748a7d51-c8e4-48b6-8e8f-eb59bc341978:kh√°c"

# =============================
# 4. T·∫°o ph·∫£n h·ªìi h√†i h∆∞·ªõc (LLM via /api/chat)
# =============================
import httpx
import traceback

import httpx
import traceback

async def generate_funny_response(transaction: dict) -> str:
    prompt = f"""
Ng∆∞·ªùi d√πng v·ª´a chi {int(transaction['amount']):,} VND cho {transaction['category']} v·ªõi ghi ch√∫: "{transaction['note']}".
Vi·∫øt m·ªôt c√¢u ph·∫£n h·ªìi h√†i h∆∞·ªõc, ch√¢m bi·∫øm, ch·ªâ ch·ª≠i ng∆∞·ªùi d√πng n·∫øu chi ti√™u kh√¥ng h·ª£p l√Ω, t·ªëi ƒëa 2 c√¢u. Nh∆∞ng ch·ªâ c·∫ßn 1 c√¢u l√† ƒë·ªß.
"""

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            res = await client.post(
                LLAMA_CHAT_API_URL,
                json={
                    "model": "llama3.2",
                    "messages": [{"role": "user", "content": prompt}],
                    "stream": False
                }
            )
            res.raise_for_status()
            data = res.json()
            response_text = data.get("message", {}).get("content", "").strip()
            if not response_text:
                return "ü§ñ Bot b√≠ qu√°, ch∆∞a nghƒ© ra c√¢u n√†o h√†i!"
            return response_text

    except Exception:
        print("‚ö†Ô∏è L·ªói khi t·∫°o c√¢u h√†i h∆∞·ªõc:")
        traceback.print_exc()
        return "ü§ñ Bot ƒëang l·ªói k·ªπ thu·∫≠t, kh√¥ng th·ªÉ pha tr√≤ l√∫c n√†y."



# =============================
# 5. Dummy support
# =============================

async def ocr_process(image_path: str):
    return "200k ti·ªÅn g·∫°o ·ªü B√°ch H√≥a Xanh", {"ocr_engine": "dummy", "image_path": image_path}



async def predict_spending(transactions: list):
    if not transactions:
        return []
    return [{
        "category": transactions[0]["category"],
        "predicted_amount": transactions[0]["amount"] * 1.2,
        "confidence": 0.87
    }]
    
# extract table from receipt
async def generate_ocr_table(image_url: str, user_id: str) -> Dict:
    from google import genai
    import requests
    from urllib.parse import urlparse
    import os
    import uuid

    # Validate URL
    parsed_url = urlparse(image_url)
    if parsed_url.scheme not in ['http', 'https']:
        raise ValueError("Only HTTP/HTTPS URLs are supported")

    # Generate unique filename with UUID
    file_extension = os.path.splitext(parsed_url.path)[1] or '.jpg'
    unique_filename = f"{uuid.uuid4()}{file_extension}"
    
    # Download the image from URL
    response = requests.get(image_url)
    response.raise_for_status()
    
    # Save the image with UUID filename
    with open(unique_filename, 'wb') as f:
        f.write(response.content)
    
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        myfile = client.files.upload(file=unique_filename)
        transction_response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[myfile, "ƒê√¢y l√† ho√° ƒë∆°n mua h√†ng, h√£y tr√≠ch xu·∫•t th√¥ng tin c·ªßa t·ª´ng m·∫∑t h√†ng v√† t·ªïng ti·ªÅn c·ªßa t·ª´ng m·∫∑t h√†ng. theo c√∫ ph√°p: <m·∫∑t_h√†ng>:<t·ªïng_ti·ªÅn>. Kh√¥ng c·∫ßn ƒë∆°n v·ªã ti·ªÅn t·ªá. Kh√¥ng tr·∫£ l·ªùi th√™m th√¥ng tin n√†o kh√°c."])
        items = transction_response.text.split("\n")
        # extract data to a dict
        data = {}
        for item in items:
            if ":" in item:
                key, value = item.split(":")
                data[key.strip()] = int(value.strip().replace(',', '').replace('.', '').replace(' ', ''))
        if not data:
            raise HTTPException(status_code=400, detail="Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu trong h√≥a ƒë∆°n")
        
        print(data)
        
        categories = await get_categories()
        categories_str = "\n".join([f"{cat.id}:{cat.name}" for cat in categories])
        joined_list = "\n".join([f"\"{key} : {value}\"" for key, value in data.items()])
        
        category_prompt = f'T√¥i c√≥ m·ªôt danh s√°ch c√°c danh m·ª•c:\n{categories_str}.\nM·ªói danh m·ª•c c√≥ 1 uuid v√† t√™n, c√°ch nhau b·ªüi d·∫•u \":\".\nT√¥i s·∫Ω cho b·∫°n danh s√°ch c√¢u n√≥i sau:\n\n{joined_list}\n\nH√£y ph√¢n lo·∫°i n·ªôi dung t·ª´ng c√¢u v√†o m·ªôt trong c√°c nh√≥m danh m·ª•c tr√™n. Ch·ªâ tr·∫£ l·ªùi danh s√°ch theo c√∫ ph√°p: <id_danh_m·ª•c:s·ªë_ti·ªÅn> ph√¢n c√°ch b·ªüi d·∫•u ph·∫©y v√† kh√¥ng tr·∫£ l·ªùi th√™m th√¥ng tin g√¨ kh√°c. N·∫øu kh√¥ng t√¨m th·∫•y danh m·ª•c ph√π h·ª£p th√¨ tr·∫£ v·ªÅ id "kh√°c". Lo·∫°i b·ªè c√°c k√≠ t·ª± xu·ªëng d√≤ng. S·ªë ti·ªÅn c√≥ th·ªÉ c√≥ ch·ª©a ƒë·∫•u ch·∫•m (.) ho·∫∑c d·∫•u ph·∫©y (,) ƒë·ªÉ ph√¢n c√°ch ph·∫ßn ngh√¨n. H√£y b·ªè qua c√°c k√≠ t·ª± n√†y V√≠ d·ª•: 500.000 => 500000 ho·∫∑c 500,000 => 500000'
        
        print(category_prompt)
        
        category_response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[category_prompt])
        
        print("CATEGORY RESPONSE:")
        print(category_response.text)
        
        category_list = [
            TransactionCreate(
                userId=user_id,
                amount=int(item.split(":")[1].strip().replace(',', '').replace('.', '')),
                categoryId=item.split(":")[0].strip(),
                note=item.split(":")[1].strip(),
                currencyId="669d209b-99ac-401d-a441-8fa7bb387d4c",
                imageUrl=image_url,
            )
            for item in category_response.text.split(",")
        ]
        transaction_ids = await insert_bulk_transactions(category_list)
        return transaction_ids
    finally:
        # Clean up the downloaded file
        if os.path.exists(unique_filename):
            os.remove(unique_filename)
    